{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1f5c7-6226-4a13-b471-2358ed97eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_converter.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import streamlit as st\n",
    "import re\n",
    "\n",
    "def clean_header(headers):\n",
    "    headers = [str(h).strip() if h else \"\" for h in headers]\n",
    "    seen = {}\n",
    "    new = []\n",
    "    for h in headers:\n",
    "        if h == \"\":\n",
    "            h = \"Extra\"\n",
    "        if h in seen:\n",
    "            seen[h] += 1\n",
    "            new.append(f\"{h}_{seen[h]}\")\n",
    "        else:\n",
    "            seen[h] = 1\n",
    "            new.append(h)\n",
    "    return new\n",
    "\n",
    "def ensure_unique_columns(columns):\n",
    "    seen = {}\n",
    "    unique = []\n",
    "    for c in columns:\n",
    "        if c in seen:\n",
    "            seen[c] += 1\n",
    "            unique.append(f\"{c}_{seen[c]}\")\n",
    "        else:\n",
    "            seen[c] = 1\n",
    "            unique.append(c)\n",
    "    return unique\n",
    "\n",
    "def read_pdf_with_plumber(pdf_path):\n",
    "    \"\"\"\n",
    "    Read tables from a PDF using pdfplumber.\n",
    "    pdfplumber is imported lazily so the module can be imported even if the package\n",
    "    isn't installed (useful for deploy-time diagnostics).\n",
    "    \"\"\"\n",
    "    # Lazy import\n",
    "    try:\n",
    "        import pdfplumber\n",
    "    except ModuleNotFoundError:\n",
    "        # Raise a clear runtime error so callers can handle it; show instructions in Streamlit UI\n",
    "        raise RuntimeError(\n",
    "            \"Missing dependency 'pdfplumber'. Install it (pip install pdfplumber) \"\n",
    "            \"or add it to requirements.txt and redeploy.\"\n",
    "        )\n",
    "\n",
    "    all_tables = []\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages, start=1):\n",
    "                tables = page.extract_tables()\n",
    "                if not tables:\n",
    "                    continue\n",
    "                for t in tables:\n",
    "                    if not t:\n",
    "                        continue\n",
    "                    df = pd.DataFrame(t)\n",
    "                    header_row = None\n",
    "                    for j, row in df.iterrows():\n",
    "                        if any(str(x).strip() for x in row):\n",
    "                            header_row = j\n",
    "                            break\n",
    "                    if header_row is not None:\n",
    "                        headers = clean_header(df.iloc[header_row].tolist())\n",
    "                        df = df.iloc[header_row + 1 :].reset_index(drop=True)\n",
    "                        df.columns = headers\n",
    "                    else:\n",
    "                        df.columns = [f\"Col_{x}\" for x in range(len(df.columns))]\n",
    "                    df.columns = ensure_unique_columns(df.columns)\n",
    "                    df[\"Page\"] = i\n",
    "                    all_tables.append(df)\n",
    "    except Exception as e:\n",
    "        # bubble up a clear error for the caller (UI can catch and show it)\n",
    "        raise RuntimeError(f\"PDF read error for '{pdf_path}': {e}\")\n",
    "\n",
    "    if not all_tables:\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        df = pd.concat(all_tables, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"PDF merge error: {e}\")\n",
    "    return df\n",
    "\n",
    "def standardize_columns(df):\n",
    "    rename_map = {\n",
    "        \"code\": \"Sku\", \"sku\": \"Sku\", \"product code\": \"Sku\", \"item code\": \"Sku\",\n",
    "        \"description\": \"Product\", \"product\": \"Product\", \"product description\": \"Product\",\n",
    "        \"cost price\": \"Cost_Price\", \"barcode\": \"Barcode\", \"location\": \"Location\",\n",
    "        \"outstanding\": \"Outstanding\", \"qty\": \"Outstanding\", \"quantity\": \"Outstanding\",\n",
    "        \"case size\": \"Case_Size\", \"case_size\": \"Case_Size\"\n",
    "    }\n",
    "    clean_cols = []\n",
    "    for c in df.columns:\n",
    "        cname = str(c).strip().lower()\n",
    "        mapped = cname\n",
    "        for k, v in rename_map.items():\n",
    "            if k in cname:\n",
    "                mapped = v\n",
    "                break\n",
    "        clean_cols.append(mapped)\n",
    "    df.columns = clean_cols\n",
    "    return df\n",
    "\n",
    "def convert_pdf_to_csv(pdf_path):\n",
    "    \"\"\"\n",
    "    Reads PDF, extracts tables, standardizes, saves CSV in same dir with suffix _extracted.csv\n",
    "    Returns the CSV path or None if extraction produced no data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = read_pdf_with_plumber(pdf_path)\n",
    "    except RuntimeError as e:\n",
    "        # Let the caller/UI see the message; in Streamlit pages it's fine to show st.error\n",
    "        st.error(str(e))\n",
    "        return None\n",
    "\n",
    "    if df.empty:\n",
    "        st.info(\"No tables found in the provided PDF.\")\n",
    "        return None\n",
    "\n",
    "    df = standardize_columns(df)\n",
    "    df.columns = ensure_unique_columns(df.columns)\n",
    "    # keep relevant cols if present\n",
    "    keep_cols = [\"Sku\",\"Product\",\"Cost_Price\",\"Barcode\",\"Location\",\"Outstanding\",\"Case_Size\"]\n",
    "    df = df[[c for c in df.columns if c in keep_cols]]\n",
    "    if \"Outstanding\" in df.columns:\n",
    "        df[\"Outstanding\"] = df[\"Outstanding\"].astype(str).str.replace(\",\",\"\")\n",
    "        df[\"Outstanding\"] = df[\"Outstanding\"].str.extract(r\"(\\d+)\", expand=False)\n",
    "        df[\"Outstanding\"] = pd.to_numeric(df[\"Outstanding\"], errors=\"coerce\")\n",
    "    df = df.dropna(how=\"all\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    csv_path = os.path.splitext(pdf_path)[0] + \"_extracted.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barcode_demo",
   "language": "python",
   "name": "barcode_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
